{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "86643056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "94c10da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "try:\n",
    "    russian_stopwords = stopwords.words('russian')\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    russian_stopwords = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d785f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bodies = pd.read_csv('./data/train_bodies.csv')\n",
    "test_bodies = pd.read_csv('./data/test_bodies.csv')\n",
    "\n",
    "train_stances = pd.read_csv('./data/train_stances.csv')\n",
    "test_stances = pd.read_csv('./data/test_stances_unlebeledb.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd66e4",
   "metadata": {},
   "source": [
    "# Проведем предобработку данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab71a22",
   "metadata": {},
   "source": [
    "## Объединим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2a41c0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_stances.merge(train_bodies, on='Body ID', how='left')\n",
    "test_data = test_stances.merge(test_bodies, on='Body ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554f76f8",
   "metadata": {},
   "source": [
    "## Проведем предобработку русского языка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f20f3305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str) or len(text) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^а-яё\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in russian_stopwords and len(word) > 2]\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16b0c91",
   "metadata": {},
   "source": [
    "## Обработка заголовков и текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "04fc37aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['headline_clean'] = train_data['Headline'].apply(preprocess_text)\n",
    "train_data['body_clean'] = train_data['articleBody'].apply(preprocess_text)\n",
    "\n",
    "test_data['headline_clean'] = test_data['Headline'].apply(preprocess_text)\n",
    "test_data['body_clean'] = test_data['articleBody'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e0aad4",
   "metadata": {},
   "source": [
    "## Создадим комбинированные признаки (заголовок + начало текста)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "48b1fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(row, max_body_words=100):\n",
    "    headline = row['headline_clean']\n",
    "    body_words = row['body_clean'].split()[:max_body_words]\n",
    "    body = ' '.join(body_words)\n",
    "    return f\"{headline} {body}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4c20b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['combined_text'] = train_data.apply(combine_features, axis=1)\n",
    "test_data['combined_text'] = test_data.apply(combine_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f11d78dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[train_data['combined_text'].str.len() > 10].reset_index(drop=True)\n",
    "test_data = test_data[test_data['combined_text'].str.len() > 10].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "06992b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Статистика длины комбинированных текстов (в словах):\n",
      "count    4408.000000\n",
      "mean      100.833711\n",
      "std        15.256562\n",
      "min         9.000000\n",
      "25%       101.000000\n",
      "50%       107.000000\n",
      "75%       109.000000\n",
      "max       125.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_data['text_length'] = train_data['combined_text'].str.split().str.len()\n",
    "print(f\"\\nСтатистика длины комбинированных текстов (в словах):\")\n",
    "print(train_data['text_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409596a0",
   "metadata": {},
   "source": [
    "## Подготовим целевую переменную\n",
    "---\n",
    "где:\n",
    "* Реальная новость - 1\n",
    "* Фейк - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5192543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'agree': 1, 'disagree': 0}\n",
    "\n",
    "train_data['label'] = train_data['Stance'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee75982",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c504b3b",
   "metadata": {},
   "source": [
    "## Загрузим эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bf5e5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [text.split() for text in train_data['body_clean']] + [text.split() for text in train_data['headline_clean']]\n",
    "w2v = Word2Vec(sentences, vector_size=300, window=5, min_count=3, sg=1, workers=4, epochs=10)\n",
    "kv = w2v.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c5e408",
   "metadata": {},
   "source": [
    "## Функция для получения усреднённого вектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "909d1ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_vector(tokens, kv_model):\n",
    "    vecs = [kv_model[w] for w in tokens if w in kv_model]\n",
    "    if not vecs:\n",
    "        return np.zeros(kv_model.vector_size, dtype=np.float32)\n",
    "    return np.vstack(vecs).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e904aad7",
   "metadata": {},
   "source": [
    "## Сбор признаков: headline_vec, body_vec, косинусная близость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cf6b10a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    nu, nv = np.linalg.norm(u), np.linalg.norm(v)\n",
    "    if nu == 0 or nv == 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(u, v) / (nu * nv))\n",
    "\n",
    "def jaccard(a_tokens, b_tokens):\n",
    "    A, B = set(a_tokens), set(b_tokens)\n",
    "    if not A and not B:\n",
    "        return 0.0\n",
    "    return len(A & B) / max(1, len(A | B))\n",
    "\n",
    "def overlap_ratio(a_tokens, b_tokens):\n",
    "    A, B = set(a_tokens), set(b_tokens)\n",
    "    if not A:\n",
    "        return 0.0\n",
    "    return len(A & B) / len(A)\n",
    "\n",
    "def elementwise_stats(h_vec, b_vec):\n",
    "    diff = np.abs(h_vec - b_vec)              # |h - b|\n",
    "    prod = h_vec * b_vec                      # h ⊙ b\n",
    "    l2 = np.linalg.norm(h_vec - b_vec)        # ||h - b||\n",
    "    return diff, prod, l2\n",
    "\n",
    "def build_features(df, kv, max_len=150):\n",
    "    H, B, COS, JAC, OVR, L2, DIFF, PROD = [], [], [], [], [], [], [], []\n",
    "    for _, row in df.iterrows():\n",
    "        htoks = row['headline_clean'].split()[:max_len]\n",
    "        btoks = row['body_clean'].split()[:max_len]\n",
    "\n",
    "        h_vec = doc_vector(htoks, kv)\n",
    "        b_vec = doc_vector(btoks, kv)\n",
    "\n",
    "        # базовые эмбеддинги\n",
    "        H.append(h_vec); B.append(b_vec)\n",
    "\n",
    "        # связи\n",
    "        COS.append(cosine(h_vec, b_vec))\n",
    "        JAC.append(jaccard(htoks, btoks))\n",
    "        OVR.append(overlap_ratio(htoks, btoks))\n",
    "\n",
    "        # контрастные признаки\n",
    "        diff, prod, l2 = elementwise_stats(h_vec, b_vec)\n",
    "        DIFF.append(diff); PROD.append(prod); L2.append(l2)\n",
    "\n",
    "    H = np.vstack(H); B = np.vstack(B)\n",
    "    COS = np.array(COS).reshape(-1, 1)\n",
    "    JAC = np.array(JAC).reshape(-1, 1)\n",
    "    OVR = np.array(OVR).reshape(-1, 1)\n",
    "    L2  = np.array(L2).reshape(-1, 1)\n",
    "    DIFF = np.vstack(DIFF)     # размер [N, d]\n",
    "    PROD = np.vstack(PROD)     # размер [N, d]\n",
    "\n",
    "    # Итоговый признак: [h, b, |h-b|, h⊙b, cos, jaccard, overlap, l2]\n",
    "    X = np.hstack([H, B, DIFF, PROD, COS, JAC, OVR, L2])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae6c0a",
   "metadata": {},
   "source": [
    "## Подготовка X и y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "54168b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = build_features(train_data, kv)\n",
    "y = train_data['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35570ba",
   "metadata": {},
   "source": [
    "## Разделим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3ad28848",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aacad61",
   "metadata": {},
   "source": [
    "## Обучим модель логистической регрессии и прогоним по метрикам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "acd7b855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 0.9320\n",
      "Val F1: 0.9307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9229    0.9437    0.9332       444\n",
      "           1     0.9416    0.9201    0.9307       438\n",
      "\n",
      "    accuracy                         0.9320       882\n",
      "   macro avg     0.9322    0.9319    0.9320       882\n",
      "weighted avg     0.9322    0.9320    0.9320       882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=2000, C=2.0, solver='liblinear', class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "print(f\"Val Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(f\"Val F1: {f1_score(y_val, y_pred):.4f}\")\n",
    "print(classification_report(y_val, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3db76e4",
   "metadata": {},
   "source": [
    "## Сохраним модель, эмбеддинги и метаданные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ad367bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель\n",
    "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
    "with open(\"models/fake_news_w2v_lr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "# Эмбеддинги\n",
    "kv.save(\"models/w2v_vectors.kv\")\n",
    "\n",
    "# Метаданные\n",
    "metrics = {\n",
    "    \"best_model_name\": \"LogisticRegression+W2V\",\n",
    "    \"val_accuracy\": float(accuracy_score(y_val, y_pred)),\n",
    "    \"val_f1\": float(f1_score(y_val, y_pred)),\n",
    "    \"vector_size\": kv.vector_size\n",
    "}\n",
    "with open(\"models/metrics.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7fd268",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b7cb0e",
   "metadata": {},
   "source": [
    "## Разделим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bb3a91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68776a02",
   "metadata": {},
   "source": [
    "## Разделим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c89d54a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = train_data['combined_text']\n",
    "# y = train_data['label']\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bd8f5d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"\\nРаспределение классов в train:\")\n",
    "# print(y_train.value_counts())\n",
    "# print(f\"\\nРаспределение классов в validation:\")\n",
    "# print(y_val.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c613e",
   "metadata": {},
   "source": [
    "## Векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e5c50745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(\n",
    "#     max_features=8000,\n",
    "#     ngram_range=(1, 2),  \n",
    "#     min_df=3,\n",
    "#     max_df=0.85,\n",
    "#     sublinear_tf=True\n",
    "# )\n",
    "\n",
    "# X_train_vec = vectorizer.fit_transform(X_train)\n",
    "# X_val_vec = vectorizer.transform(X_val)\n",
    "\n",
    "# print(f\"✓ Размерность векторов: {X_train_vec.shape[1]} признаков\")\n",
    "# print(f\"✓ Разреженность: {(1 - X_train_vec.nnz / (X_train_vec.shape[0] * X_train_vec.shape[1])) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0fc8e5",
   "metadata": {},
   "source": [
    "## Обучим 3 модели и в последствии выберем лучшую\n",
    "---\n",
    "* Logistic Regression\n",
    "* Naive Bayes\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b45c8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {\n",
    "#     'Logistic Regression': LogisticRegression(\n",
    "#         max_iter=1000,\n",
    "#         C=1,\n",
    "#         random_state=42,\n",
    "#         class_weight='balanced'  # Для несбалансированных классов\n",
    "#     ),\n",
    "#     'Naive Bayes': MultinomialNB(alpha=0.1),\n",
    "#     'Random Forest': RandomForestClassifier(\n",
    "#         n_estimators=100,\n",
    "#         max_depth=30,\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1,\n",
    "#         class_weight='balanced'\n",
    "#     )\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "26487cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "\n",
    "# for name, model in models.items():\n",
    "#     print(f\"\\n--- {name} ---\")\n",
    "\n",
    "#     print(\"  Обучение модели...\")\n",
    "#     model.fit(X_train_vec, y_train)\n",
    "    \n",
    "#     y_train_pred = model.predict(X_train_vec)\n",
    "#     y_val_pred = model.predict(X_val_vec)\n",
    "    \n",
    "#     # Метрики\n",
    "#     train_acc = accuracy_score(y_train, y_train_pred)\n",
    "#     val_acc = accuracy_score(y_val, y_val_pred)\n",
    "#     val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    \n",
    "#     print(f\"  Train Accuracy: {train_acc:.4f}\")\n",
    "#     print(f\"  Val Accuracy:   {val_acc:.4f}\")\n",
    "#     print(f\"  Val F1-Score:   {val_f1:.4f}\")\n",
    "    \n",
    "#     print(f\"\\n  Classification Report (Validation):\")\n",
    "#     print(classification_report(y_val, y_val_pred,\n",
    "#                                 target_names=['Фейк (disagree)', 'Реальная (agree)'],\n",
    "#                                 digits=4))\n",
    "    \n",
    "#     results[name] = {\n",
    "#         'model': model,\n",
    "#         'train_acc': train_acc,\n",
    "#         'val_acc': val_acc,\n",
    "#         'val_f1': val_f1,\n",
    "#         'predictions': y_val_pred\n",
    "#     }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ef495",
   "metadata": {},
   "source": [
    "## Проверим на метриках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "096a83da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# # График 1: Accuracy\n",
    "# model_names = list(results.keys())\n",
    "# train_accs = [results[name]['train_acc'] for name in model_names]\n",
    "# val_accs = [results[name]['val_acc'] for name in model_names]\n",
    "\n",
    "# x = np.arange(len(model_names))\n",
    "# width = 0.35\n",
    "\n",
    "# axes[0, 0].bar(x - width/2, train_accs, width, label='Train', alpha=0.8, color='skyblue')\n",
    "# axes[0, 0].bar(x + width/2, val_accs, width, label='Validation', alpha=0.8, color='coral')\n",
    "# axes[0, 0].set_xlabel('Модель')\n",
    "# axes[0, 0].set_ylabel('Accuracy')\n",
    "# axes[0, 0].set_title('Сравнение точности моделей', fontweight='bold')\n",
    "# axes[0, 0].set_xticks(x)\n",
    "# axes[0, 0].set_xticklabels(model_names, rotation=15, ha='right')\n",
    "# axes[0, 0].legend()\n",
    "# axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# # График 2: F1-Score\n",
    "# val_f1s = [results[name]['val_f1'] for name in model_names]\n",
    "\n",
    "# axes[0, 1].bar(model_names, val_f1s, alpha=0.8, color='lightgreen')\n",
    "# axes[0, 1].set_xlabel('Модель')\n",
    "# axes[0, 1].set_ylabel('F1-Score')\n",
    "# axes[0, 1].set_title('F1-Score на валидации', fontweight='bold')\n",
    "# axes[0, 1].tick_params(axis='x', rotation=15)\n",
    "# axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# # График 3: Confusion Matrix\n",
    "# best_model_name = max(results, key=lambda x: results[x]['val_acc'])\n",
    "# best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "# cm = confusion_matrix(y_val, best_predictions)\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0],\n",
    "#             xticklabels=['Фейк', 'Реальная'],\n",
    "#             yticklabels=['Фейк', 'Реальная'])\n",
    "# axes[1, 0].set_title(f'Confusion Matrix - {best_model_name}', fontweight='bold')\n",
    "# axes[1, 0].set_ylabel('Истинные метки')\n",
    "# axes[1, 0].set_xlabel('Предсказания')\n",
    "\n",
    "# # График 4: Распределение длины текстов\n",
    "# axes[1, 1].hist([train_data[train_data['label']==0]['text_length'],\n",
    "#                  train_data[train_data['label']==1]['text_length']],\n",
    "#                 bins=30, label=['Фейк', 'Реальная'], alpha=0.7, color=['red', 'green'])\n",
    "# axes[1, 1].set_xlabel('Длина текста (слов)')\n",
    "# axes[1, 1].set_ylabel('Частота')\n",
    "# axes[1, 1].set_title('Распределение длины текстов', fontweight='bold')\n",
    "# axes[1, 1].legend()\n",
    "# axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('./assets/fake_news_analysis.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f8b76d",
   "metadata": {},
   "source": [
    "## Сохраним модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "73a1ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = results[best_model_name]['model']\n",
    "# best_acc = results[best_model_name]['val_acc']\n",
    "# best_f1 = results[best_model_name]['val_f1']\n",
    "\n",
    "# print(f\"Лучшая модель: {best_model_name}\")\n",
    "# print(f\"Validation Accuracy: {best_acc:.4f}\")\n",
    "# print(f\"Validation F1-Score: {best_f1:.4f}\")\n",
    "\n",
    "# # Сохранение\n",
    "# with open('./models/fake_news_detector.pkl', 'wb') as f:\n",
    "#     pickle.dump(best_model, f)\n",
    "\n",
    "# with open('./models/tfidf_vectorizer.pkl', 'wb') as f:\n",
    "#     pickle.dump(vectorizer, f)\n",
    "\n",
    "# with open('./models/label_mapping.pkl', 'wb') as f:\n",
    "#     pickle.dump(label_mapping, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c7d148a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from pathlib import Path\n",
    "\n",
    "# metrics = {\n",
    "#     \"best_model_name\": best_model_name,\n",
    "#     \"val_accuracy\": float(best_acc),\n",
    "#     \"val_f1\": float(best_f1)\n",
    "# }\n",
    "# Path(\"results/metrics\").mkdir(parents=True, exist_ok=True)\n",
    "# with open(\"results/metrics/metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(metrics, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbba788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
